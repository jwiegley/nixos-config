groups:
  - name: storage_alerts
    interval: 30s
    rules:
      # ZFS alerts
      - alert: ZFSPoolDegraded
        expr: node_zfs_zpool_health{state!="online"} > 0
        for: 1m
        labels:
          severity: critical
          category: storage
          service: zfs
        annotations:
          summary: "ZFS pool degraded on {{ $labels.instance }}"
          description: "ZFS pool {{ $labels.pool }} is in {{ $labels.state }} state"

      - alert: ZFSPoolCapacityHigh
        expr: node_zfs_zpool_capacity > 80
        for: 5m
        labels:
          severity: warning
          category: storage
          service: zfs
        annotations:
          summary: "ZFS pool capacity high"
          description: "ZFS pool {{ $labels.pool }} is at {{ $value }}% capacity"

      - alert: ZFSPoolCapacityCritical
        expr: node_zfs_zpool_capacity > 90
        for: 1m
        labels:
          severity: critical
          category: storage
          service: zfs
        annotations:
          summary: "ZFS pool capacity critical"
          description: "ZFS pool {{ $labels.pool }} is at {{ $value }}% capacity"

      - alert: ZFSPoolFreeSpaceLow
        expr: zfs_dataset_available_bytes{name=~"^(tank|gdrive)$",type="filesystem"} < 500 * 1024 * 1024 * 1024
        for: 1h
        labels:
          severity: warning
          category: storage
          service: zfs
        annotations:
          summary: "ZFS pool {{ $labels.pool }} has less than 500GB free"
          description: "Pool {{ $labels.pool }} has {{ $value | humanize1024 }}B available"

      - alert: ZFSSnapshotAgeTooOld
        expr: (time() - node_zfs_snapshot_timestamp) > 86400
        for: 5m
        labels:
          severity: warning
          category: storage
          service: zfs
        annotations:
          summary: "ZFS snapshot is too old"
          description: "ZFS snapshot {{ $labels.snapshot }} is older than 24 hours"

      # Backup alerts - Restic repository checks
      - alert: ResticCheckFailed
        expr: restic_check_success{repository!=""} == 0
        for: 5m
        labels:
          severity: critical
          category: storage
          service: restic
        annotations:
          summary: "Restic repository check failed"
          description: "Restic check for repository {{ $labels.repository }} has failed"

      # Alert threshold: 30 hours (108000s)
      # Rationale: Backups run daily at 02:00, metrics collection runs every 6 hours.
      # The 30h threshold prevents false alerts during the ~40min window each day
      # when metrics are stale (between 28h mark and next metrics collection at 06:39).
      # With 30h threshold, there's a 2h buffer before alerting on actual failures.
      - alert: ResticNoRecentSnapshot
        expr: (time() - restic_last_snapshot_timestamp_seconds{repository!=""}) > 108000
        for: 10m
        labels:
          severity: warning
          category: storage
          service: restic
        annotations:
          summary: "Restic repository has no recent snapshots"
          description: "Repository {{ $labels.repository }} hasn't had a snapshot in over 30 hours (last: {{ $value | humanizeDuration }} ago)"

      - alert: ResticNoSnapshots
        expr: restic_snapshots_total{repository!=""} == 0
        for: 5m
        labels:
          severity: critical
          category: storage
          service: restic
        annotations:
          summary: "Restic repository has no snapshots"
          description: "Repository {{ $labels.repository }} has no snapshots at all"

      - alert: ResticRepositorySizeGrowing
        expr: rate(restic_repo_size_bytes{repository!=""}[24h]) > 10737418240
        for: 1h
        labels:
          severity: info
          category: storage
          service: restic
        annotations:
          summary: "Restic repository growing rapidly"
          description: "Repository {{ $labels.repository }} is growing by more than 10GB per day"